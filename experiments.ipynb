{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "experiments.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blufzzz/two-stream-dyntex-synth/blob/spatio-temporal-statistics/experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "CEzEsAQYLQe_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Here is experiments with approach described in \n",
        "\n",
        "http://arxiv.org/abs/1702.07006   \n"
      ]
    },
    {
      "metadata": {
        "id": "V0sEI-_Y7nJk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "66e165ab-5c99-4325-dd0b-31516d2b1aa7"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0TxNtKF4ezRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c6d39c23-17e6-43ce-b88b-fca25320ce74"
      },
      "cell_type": "code",
      "source": [
        "cd ./gdrive/My\\ Drive/Colab Notebooks/two-stream-dyntex-synth"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: './gdrive/My Drive/Colab Notebooks/two-stream-dyntex-synth'\n",
            "/content/gdrive/My Drive/Colab Notebooks/two-stream-dyntex-synth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2016-07-26T13:28:08.033450",
          "start_time": "2016-07-26T13:28:02.561849"
        },
        "id": "wzf2NTLwLQfB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "from scipy.optimize import minimize\n",
        "import tensorflow as tf\n",
        "sys.path.append('/content/gdrive/My Drive/Colab Notebooks/two-stream-dyntex-synth/src') \n",
        "from utilities import load_image, load_images, vgg_process, vgg_deprocess\n",
        "from appearance_descriptor import AppearanceDescriptor\n",
        "from optimizer import Optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k3B8yqQKHLat",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "config_proto = tf.ConfigProto()\n",
        "config_proto.gpu_options.allow_growth = True\n",
        "config_proto.allow_soft_placement = True\n",
        "config_proto.log_device_placement = False\n",
        "my_config = {}\n",
        "my_config['batch_size'] = 1\n",
        "my_config['iterations'] = 6000\n",
        "my_config['snapshot_frequency'] = 1000\n",
        "my_config['network_out_frequency'] = 100\n",
        "my_config['log_frequency'] = 100\n",
        "my_config['gpu'] = 0\n",
        "my_config['dt'] = 3\n",
        "my_config['run_id'] = \"whoa_wood!\"\n",
        "my_config['dynamics_model'] = 'MSOEnet'\n",
        "\n",
        "config = {'tf': config_proto, 'user': my_config}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JtaXdjn0FJ7g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import skimage.io\n",
        "from utilities import check_snapshots, vgg_deprocess\n",
        "import time\n",
        "import datetime\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "class Optimizer(object):\n",
        "\n",
        "    def __init__(self, graph, input_dimension, input_frame_count,\n",
        "                 target_dynamic_path, target_static_path, config):\n",
        "        self.graph = graph\n",
        "        self.input_dimension = input_dimension\n",
        "        self.input_frame_count = input_frame_count\n",
        "        self.target_dynamic_path = target_dynamic_path\n",
        "        self.target_static_path = target_static_path\n",
        "        self.user_config = config['user']\n",
        "        self.tf_config = config['tf']\n",
        "\n",
        "    def print_info(self, losses):\n",
        "        i = self.iterations_so_far\n",
        "        iterations = self.user_config['iterations']\n",
        "        run_id = self.user_config['run_id']\n",
        "\n",
        "        time_diff = time.time() - self.last_print\n",
        "        it_per_sec = 1 / time_diff\n",
        "        remaining_it = iterations - i\n",
        "        eta = remaining_it / it_per_sec\n",
        "        eta_string = str(datetime.timedelta(seconds=eta))\n",
        "\n",
        "        print_string = '(%s) Iteration %d: dynamic texture loss: %f ' \\\n",
        "                       'appearance loss: %f dynamics ' \\\n",
        "                       'loss: %f ' \\\n",
        "                       'iter per/s: %f ETA: %s' % (run_id, i + 1,\n",
        "                                                   losses[0],\n",
        "                                                   losses[1],\n",
        "                                                   losses[2],\n",
        "                                                   it_per_sec,\n",
        "                                                   eta_string)\n",
        "        print print_string\n",
        "        self.last_print = time.time()\n",
        "\n",
        "    def minimize_callback(self, dyntex_loss, appearance_loss,\n",
        "                          dynamics_loss, output, summaries):\n",
        "        # if hasattr(self, 'current_loss'):\n",
        "        #     self.past_loss = self.current_loss\n",
        "        # self.current_loss = dyntex_loss\n",
        "        # for cleanliness\n",
        "        i = self.iterations_so_far\n",
        "        snapshot_frequency = self.user_config['snapshot_frequency']\n",
        "        network_out_frequency = self.user_config['network_out_frequency']\n",
        "        log_frequency = self.user_config['log_frequency']\n",
        "        run_id = self.user_config['run_id']\n",
        "\n",
        "        # print training information\n",
        "        self.print_info([dyntex_loss, appearance_loss, dynamics_loss])\n",
        "\n",
        "        if (i + 1) % snapshot_frequency == 0:\n",
        "            print 'Saving snapshot...'\n",
        "            try:\n",
        "                os.makedirs('snapshots/' + run_id)\n",
        "            except OSError:\n",
        "                if not os.path.isdir('snapshots/' + run_id):\n",
        "                    raise\n",
        "            self.saver.save(self.sess, 'snapshots/' + run_id + '/iter',\n",
        "                            global_step=i+1)\n",
        "        if (i + 1) % log_frequency == 0:\n",
        "            print 'Saving log file...'\n",
        "            #self.summary_writer.add_summary(summaries, i + 1)\n",
        "            #self.summary_writer.flush()\n",
        "\n",
        "        if (i + 1) % network_out_frequency == 0:\n",
        "            print 'Saving image(s)...'\n",
        "            try:\n",
        "                os.makedirs('data/out/' + run_id)\n",
        "            except OSError:\n",
        "                if not os.path.isdir('data/out/' + run_id):\n",
        "                    raise\n",
        "            network_out = output.reshape((-1,\n",
        "                                          self.input_frame_count,\n",
        "                                          self.input_dimension,\n",
        "                                          self.input_dimension, 3))\n",
        "            img_count = 1\n",
        "            for out in network_out:\n",
        "                frame_count = 1\n",
        "                for frame in out:\n",
        "                    img_out = vgg_deprocess(frame, no_clip=False,\n",
        "                                            unit_scale=False)\n",
        "                    filename = 'data/out/' + run_id + \\\n",
        "                        '/iter_%d_frame_%d_%d.png'\n",
        "                    skimage.io.imsave(filename %\n",
        "                                      (i + 1, frame_count,\n",
        "                                       img_count),\n",
        "                                      img_out)\n",
        "                    frame_count += 1\n",
        "                img_count += 1\n",
        "        self.iterations_so_far += 1\n",
        "\n",
        "    def step_callback(self, args):\n",
        "        if hasattr(self, 'past_loss'):\n",
        "            loss_diff = (self.past_loss - self.current_loss) / \\\n",
        "                np.amax([np.abs(self.past_loss), np.abs(self.current_loss), 1])\n",
        "            print 'f diff = ' + str(loss_diff)\n",
        "\n",
        "    def optimize(self):\n",
        "        iterations = self.user_config['iterations']\n",
        "        run_id = self.user_config['run_id']\n",
        "\n",
        "        with self.graph.as_default():\n",
        "            \"\"\"\n",
        "            Instantiate optimizer\n",
        "            \"\"\"\n",
        "            with tf.device('/gpu:' + str(self.user_config['gpu'])):\n",
        "              \n",
        "                optimizer = tf.contrib.opt.ScipyOptimizerInterface(\t\n",
        "                    self.dyntex_loss, method='L-BFGS-B',\n",
        "                    options={'maxfun': iterations,\n",
        "                             'disp': True})\n",
        "                             #'ftol': 1e-5})\n",
        "\n",
        "            \"\"\"\n",
        "            Train over iterations, printing loss at each one\n",
        "            \"\"\"\n",
        "            self.saver = tf.train.Saver(max_to_keep=0, pad_step_number=16)\n",
        "            with tf.Session(config=self.tf_config) as self.sess:\n",
        "\n",
        "                # TODO: change snapshot and log folders to be in a single\n",
        "                # location\n",
        "                # check snapshots\n",
        "                resume, self.iterations_so_far = check_snapshots(run_id)\n",
        "\t\t\t\t\n",
        "                print ('BEFORE')\n",
        "                \n",
        "                # start summary writer\n",
        "                #self.summary_writer = tf.summary.FileWriter('logs/' + run_id,\n",
        "                #                                           self.sess.graph)\n",
        "                \n",
        "                if resume:\n",
        "                    self.saver.restore(self.sess, resume)\n",
        "                else:\n",
        "                    self.sess.run(tf.global_variables_initializer()) # ^C occurs here!\n",
        "\t\t\t\t\n",
        "                print('AFTER')\n",
        "                \n",
        "                # initialize start time\n",
        "                self.last_print = time.time()\n",
        "\n",
        "                # start train loop\n",
        "                print '-------OPTIMIZING USING L-BFGS-B-------'\n",
        "                # scipy optimizer needs a callback for printing iter info\n",
        "                optimizer.minimize(self.sess,\n",
        "                                   fetches=[self.dyntex_loss,\n",
        "                                            self.appearance_loss,\n",
        "                                            self.dynamics_loss,\n",
        "                                            self.output,\n",
        "                                            self.summaries],\n",
        "                                   loss_callback=self.minimize_callback)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FYPHTJ8_6KiB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SpatialGramSynthesizer(Optimizer):\n",
        "  \n",
        "  def __init__(self, target_dynamic_path, generated_dynamic_path, dt, config, ):\n",
        "\n",
        "    Optimizer.__init__(self, tf.Graph(), 256, 12, target_dynamic_path, '',config)\n",
        "\n",
        "    with self.graph.as_default():\n",
        "      with tf.device('/gpu:' + str(self.user_config['gpu'])):\n",
        "\n",
        "        imgs = load_images(target_dynamic_path,\n",
        "                       size=(input_frame_count,\n",
        "                             input_dimension,\n",
        "                             input_dimension))\n",
        "        \n",
        "        target_dynamic_texture = [tf.to_float(\n",
        "            tf.constant(img.reshape(1, input_dimension,\n",
        "                                  input_dimension, 3)))\n",
        "                                  for img in imgs]\n",
        "\n",
        "        initial_noise = tf.random_normal([1,\n",
        "                                          input_dimension,\n",
        "                                          input_dimension, 3])\n",
        "\n",
        "        \n",
        "        output = tf.Variable(initial_noise, name='output')\n",
        "        \n",
        "        is_generated = len(os.listdir(generated_dynamic_path))\n",
        "        \n",
        "        if is_generated:\n",
        "        \n",
        "          gen_imgs = load_images(generated_dynamic_path,\n",
        "                         size=(input_frame_count,\n",
        "                               input_dimension,\n",
        "                               input_dimension))\n",
        "          \n",
        "          generated_dynamic_texture = [tf.to_float(\n",
        "            tf.constant(img.reshape(1, input_dimension,\n",
        "                                  input_dimension, 3)))\n",
        "                                  for img in gen_imgs]\n",
        "          \n",
        "        else:\n",
        "          \n",
        "          generated_dynamic_texture = []\n",
        "\n",
        "        # starting from the last (dt-1) frames we'll optimize new one (output)\n",
        "        output_within_timeframe = (target_dynamic_texture + generated_dynamic_texture)[:-(dt-1)] + [output]\n",
        "\n",
        "        self.dyntex_loss = build_spatial_gram_descriptors('spatial_gram_descriptors', 1e9)\n",
        "        \n",
        "        self.attach_summaries('summaries')\n",
        "\n",
        "  def build_spatial_gram_descriptors(self, name, weight):\n",
        "\n",
        "    with tf.get_default_graph().name_scope(name):\n",
        "        # TODO: make this user-definable\n",
        "        loss_layers = ['pool1', 'pool2',\n",
        "                       'pool3', 'pool4']\n",
        "\n",
        "        activations = []\n",
        "        activations_output = []\n",
        "        for i in range(input_frame_count):\n",
        "            # texture target is in RGB [0,1], but VGG\n",
        "            # accepts BGR [0-mean,255-mean] mean subtracted\n",
        "            input = vgg_process(target_dynamic_texture[i])\n",
        "\n",
        "            a = AppearanceDescriptor('spatial_gram_descriptor_' + str(i+1), name, input)\n",
        "\n",
        "            activations.append([a.activations_for_layer(l) for l in loss_layers])\n",
        "\n",
        "        for i in range(dt):\n",
        "\n",
        "            a_output = AppearanceDescriptor('spatial_gram_descriptor_out', name, vgg_process(output_within_timeframe[i]))\n",
        "\n",
        "            activations_output.append([a_output.activations_for_layer(l) for l in loss_layers])\n",
        "\n",
        "        Gl = [] # Spatial Grammians of the target \n",
        "        Ol = [] # Spatial Grammians of the output \n",
        "\n",
        "        for l in range(len(loss_layers)):\n",
        "\n",
        "            # gramians for this layer within different time-windows i:i+dt\n",
        "            Gl_dt = []\n",
        "\n",
        "            for i in range(opt.input_frame_count - dt + 1):\n",
        "\n",
        "                Gl_dt.append(self.compute_timewindow_gram_l(activations[i:i+dt], l))\n",
        "\n",
        "            Gl.append(tf.reduce_mean(tf.concat(Gl_dt, 0), 0))\n",
        "\n",
        "            # we take [0] to get make (N x N) tensor instead of (1 x N x N)\n",
        "            Ol.append(self.compute_timewindow_gram_l(activations_output,l)[0])\n",
        "\n",
        "        spatial_gram_loss = tf.add_n([tf.reduce_sum(tf.square(tf.subtract(G,O))) for G,O in zip(Gl, Ol)])\n",
        "\n",
        "    return tf.multiply(spatial_gram_loss, weight)\n",
        "\n",
        "\n",
        "  def compute_timewindow_gram_l(activations, layer):\n",
        "  \n",
        "    '''\n",
        "    Returns gram matrixes of activations (within time-window dt) for some layer\n",
        "    '''\n",
        "\n",
        "    # reshape activations\n",
        "\n",
        "    shape = activations[0][layer].get_shape().as_list()\n",
        "\n",
        "    # F with shape M_l x dt*N_l\n",
        "    F = tf.concat([tf.reshape(act[layer], (shape[1]*shape[2], shape[3])) for act in activations], axis = -1)\n",
        "\n",
        "    mult = tf.matmul(F,F,transpose_a = True)\n",
        "\n",
        "    # make a tensor shape: 1 x N x N instead of N x N\n",
        "    mult = tf.expand_dims(mult,0)\n",
        "\n",
        "    normalize_scale = tf.div(1.0, (shape[1]*shape[2]))\n",
        "\n",
        "    return tf.multiply(normalize_scale, mult)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gGKvmeIMNZK2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# path_vgg19 = '/content/gdrive/My Drive/Colab Notebooks/two-stream-dyntex-synth/models/vgg19_normalized.tfmodel'\n",
        "\n",
        "# with open(path_vgg19, mode='rb') as f:\n",
        "#     file_content = f.read()\n",
        "\n",
        "# graph_def = tf.GraphDef()\n",
        "# graph_def.ParseFromString(file_content)\n",
        "\n",
        "# tf.import_graph_def(graph_def, name='appearance_desrcriptor', input_map = {'images': input})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lbnpaUu45X65",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "g_def = tf.get_default_graph()\n",
        "\n",
        "g_def.get_tensor_by_name('appearance_desrcriptor/pool1:0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I4hW2F_i5FYa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for n in tf.get_default_graph().as_graph_def().node:\n",
        "  \n",
        "  print (n.name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2016-07-26T13:28:08.044257",
          "start_time": "2016-07-26T13:28:08.035124"
        },
        "id": "nzscMn-bLQfR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_model_data(model, filename):\n",
        "    \"\"\"Unpickles and loads parameters into a Lasagne model.\"\"\"\n",
        "    filename = os.path.join('./', '%s.%s' % (filename, 'params'))\n",
        "    with open(filename, 'r') as f:\n",
        "        data = pickle.load(f)\n",
        "    lasagne.layers.set_all_param_values(model, data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7bMK0rkkpug_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tex_dir = './'\n",
        "img = plt.imread('./test.png')\n",
        "img2 = preprocess('test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BPMW_vILLQfV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def list2str(liste):\n",
        "    '''\n",
        "    This functions takes a list and returns a string containing the elements of the list\n",
        "    '''\n",
        "    a=''\n",
        "    for x in range(len(liste)):\n",
        "        a+='-'+str(liste[x])\n",
        "    return a\n",
        "\n",
        "def preprocess(im_code): \n",
        "    '''\n",
        "    preprocessing of the images\n",
        "    '''\n",
        "    frame=io.imread(tex_dir+im_code+'.png').astype('uint8')\n",
        "    frame = (frame[:,:,::-1]-[103.939, 116.779, 123.68]).transpose(2,0,1)[None,:]\n",
        "    return frame.astype('float32') # 3,256,256\n",
        " \n",
        "\n",
        "def deprocess(x):\n",
        "    '''\n",
        "    deprocessing of the images\n",
        "    '''\n",
        "    i=x.reshape(3,im_size[0],im_size[1])\n",
        "    i=i.transpose(1,2,0)\n",
        "    i=i+[103.939, 116.779, 123.68]  \n",
        "    i=i[:,:,::-1] \n",
        "    i=np.uint8(i)\n",
        "    return i\n",
        "\n",
        "def resize_images(): \n",
        "    '''\n",
        "    resize the images: im_size equals im_size[0]*im_size[1]=256**2\n",
        "    the new images are saved as c_out1, ...\n",
        "    '''\n",
        "    for n in range(1,T_frames+1):\n",
        "        frame=io.imread(tex_dir+'out'+str(n)+'.png').astype(uint8)\n",
        "\n",
        "        if n==1: \n",
        "            im_size=[0,0]\n",
        "            bn=256*np.sqrt(frame.shape[0]/float(frame.shape[1]))\n",
        "            im_size[1]=int(round(256**2/bn))\n",
        "            im_size[0]=int(round(bn))\n",
        "            plt.imshow(frame)\n",
        "            plt.show()\n",
        "\n",
        "        frame = transform.resize(frame, (im_size[0], im_size[1]),\n",
        "                                order=3, preserve_range=True).astype(uint8)\n",
        "        io.imsave(tex_dir+'c_out'+str(n)+'.png', frame)\n",
        "    return im_size\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rdvtfQIsLQfY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from lasagne.utils import floatX\n",
        "\n",
        "def gram_matrix(x):\n",
        "    '''\n",
        "    calculates the gram matrix over the input\n",
        "    '''\n",
        "    x = x.flatten(ndim=3)\n",
        "    g = T.tensordot(x, x, axes=([2], [2]))\n",
        "\n",
        "    return g\n",
        "\n",
        "def my_loss(X, layer, source_gram_s):\n",
        "    '''\n",
        "    loss function for the optimisation process\n",
        "    '''\n",
        "    x = X[layer]\n",
        "    A=source_gram_s[layer]\n",
        "    G = gram_matrix(x)\n",
        "    \n",
        "    N = x.shape[1]\n",
        "    M = x.shape[2] * x.shape[3]\n",
        "    \n",
        "    loss = 1./(4 * N**2 * M**2) * ((G - A)**2).sum()\n",
        "    return loss\n",
        "\n",
        "def globalgram(A, layer):\n",
        "    '''\n",
        "    helper function\n",
        "    '''\n",
        "    a = A[layer]\n",
        "    A = gram_matrix(a)\n",
        "    return A\n",
        "\n",
        "def get_statistics(frames):\n",
        "    input_im_theano = T.tensor4()\n",
        "        \n",
        "    layers = {k: vggnet[k] for k in tex_layers}            \n",
        "    outputs = lasagne.layers.get_output(layers.values(), input_im_theano)\n",
        "    source_features = {k: theano.shared(output.eval({input_im_theano: frames}))\n",
        "            for k, output in zip(layers.keys(), outputs)}\n",
        "        \n",
        "    source_gram={k: globalgram(source_features, k) for k in tex_layers}    \n",
        "    return {k: source_gram[k].eval() for k in tex_layers}\n",
        "    \n",
        "def do_frames(source_gram_s, bounds, init, framenum):\n",
        "    '''\n",
        "    optimisation process of a new frame\n",
        "    '''\n",
        "    generated_image = theano.shared(floatX(np.random.uniform(-128, 128, (num, 3, im_size[0], im_size[1]))))\n",
        "    input_im_theano = T.tensor4()\n",
        "        \n",
        "    layers = {k: vggnet[k] for k in tex_layers}            \n",
        "\n",
        "    gen_features = lasagne.layers.get_output(layers.values(), generated_image)\n",
        "    gen_features = {k: v for k, v in zip(layers.keys(), gen_features)}\n",
        "\n",
        "    losses = []\n",
        "    for tex_layer in tex_layers:  \n",
        "        losses.append(1e9 * my_loss(gen_features, tex_layer, source_gram_s))\n",
        "        \n",
        "\n",
        "    total_loss = sum(losses) \n",
        "    grad = T.grad(total_loss, generated_image)\n",
        "\n",
        "    f_loss_grad=theano.function([], [total_loss, grad])\n",
        "    loss_list=[]        \n",
        "    def eval_loss_grad(x0):\n",
        "        x0 = floatX(x0.reshape((num, 3, im_size[0], im_size[1])))\n",
        "\n",
        "        generated_image.set_value(x0)\n",
        "        l,g=f_loss_grad() \n",
        "        \n",
        "        if predict or framenum!=framenums[0]:                        \n",
        "            for n in range(1,num):\n",
        "                g[n,:,:,:]=0\n",
        "            \n",
        "        g=np.array(g).flatten().astype('float64')     \n",
        "        return l.astype('float64'), g \n",
        "    \n",
        "\n",
        "    #optimization  \n",
        "    result = minimize(eval_loss_grad, init,\n",
        "                      method='L-BFGS-B',\n",
        "                      jac=True,\n",
        "                      bounds=bounds,\n",
        "                      options={'maxiter': 500,\n",
        "                                'maxcor': 20,\n",
        "                                'ftol': 0, 'gtol': 0})\n",
        "\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O3c_NX2iLQfd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_bounds_and_source_gram():    \n",
        "    '''\n",
        "    loops over the original images and calculates the bounds and the statistics of the dynamic texture \n",
        "    '''\n",
        "    lowerbound,upperbound=[0,0,0],[0,0,0]\n",
        "    for framenum in framenums: # range(3,4) , num = 3\n",
        "\n",
        "        frames=np.ones([num,3,im_size[0],im_size[1]]).astype('float32')\n",
        "        tmp=0\n",
        "        for n in nums:               \n",
        "            frames[tmp,:,:,:]=preprocess('c_out'+str(framenum-n))#orig frame 0\n",
        "            tmp+=1\n",
        "\n",
        "        source_gram=get_statistics(frames)\n",
        "        if framenum==framenums[0]:\n",
        "            source_gram_s=source_gram\n",
        "        else:\n",
        "            source_gram_s={k: source_gram_s[k]+source_gram[k] for k in tex_layers}\n",
        "\n",
        "        #get bounds (== the minimum/maximum of the used frames)\n",
        "        lowerbound[0]=min(lowerbound[0],frames[:,0,:,:].min())\n",
        "        lowerbound[1]=min(lowerbound[1],frames[:,1,:,:].min())\n",
        "        lowerbound[2]=min(lowerbound[2],frames[:,2,:,:].min())\n",
        "        upperbound[0]=max(upperbound[0],frames[:,0,:,:].max())\n",
        "        upperbound[1]=max(upperbound[1],frames[:,1,:,:].max())\n",
        "        upperbound[2]=max(upperbound[2],frames[:,2,:,:].max())\n",
        "    bounds = list()\n",
        "    for tmp in range(num):\n",
        "        for tmp2 in range(3):\n",
        "            for tmp3 in range(im_size[0]*im_size[1]):\n",
        "                bounds.append((lowerbound[tmp2],upperbound[tmp2]))  \n",
        "    source_gram_s={k: source_gram_s[k]/float(len(framenums)) for k in tex_layers}\n",
        "    return source_gram_s, bounds\n",
        "\n",
        "def generate_frames(source_gram_s, bounds):\n",
        "    '''\n",
        "    generates the new frames\n",
        "    '''\n",
        "    for framenum in range(framenums[0],framenums[0]+number_of_generated_frames):\n",
        "        print framenum\n",
        "        init = (scipy.randn(num,3,im_size[0],im_size[1])).astype('float32')\n",
        "\n",
        "        tmp=1\n",
        "\n",
        "        for n in nums[1:]:\n",
        "            if (framenum-n)<framenums[0]:\n",
        "                if predict:\n",
        "                    init[tmp,:,:,:]=preprocess('c_out'+str(framenum-n))\n",
        "            else:\n",
        "                init[tmp,:,:,:]=preprocess(name+str(framenum-n))\n",
        "            tmp+=1\n",
        "\n",
        "        result=do_frames(source_gram_s, bounds, init=init, framenum=framenum) \n",
        "\n",
        "\n",
        "        i=result.x.reshape(num,3,im_size[0],im_size[1])\n",
        "        i0=i[0,:,:,:]\n",
        "\n",
        "        erg0=deprocess(i0)\n",
        "        if predict==False and framenum==framenums[0]:\n",
        "            for n in nums[1:]:\n",
        "                 io.imsave(tex_dir+name+str(framenum-n)+'.png', deprocess(i[n,:,:,:])) \n",
        "\n",
        "        imshow(erg0)\n",
        "        plt.show()\n",
        "\n",
        "        print '-----------------------------------------------------------------------'\n",
        "        io.imsave(tex_dir+name+str(framenum)+'.png', erg0)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "97CEhkolLQfi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "change the parameters in the next block to choose delta t, T, ...    \n",
        "the original frames have to be in a folder called 'test/' and have to be named as out1.png, out2.png, ...\n",
        "\n",
        "**starting condition:**  \n",
        "predict=true: frames of the original video are used   \n",
        "predict=false: random initialisation"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "MjvyJwrILQfj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#---------------------------------------\n",
        "tex_dir = './two-stream-dyntex-synth/data/dynamic_textures/escalator/'\n",
        "nums=[0,1,2] # for delta t=2 use nums=[0,1], for delta t=3 use nums=[0,1,2],...\n",
        "T_frames=3 # T number of frames of the original video\n",
        "\n",
        "number_of_generated_frames=2 # number of generated frames\n",
        "predict=False # defines the starting condition\n",
        "            \n",
        "#----------------------------------------------\n",
        "\n",
        "num=len(nums)\n",
        "\n",
        "if predict:\n",
        "    name='predict'+list2str(nums)+'_'+str(T_frames-nums[-1])+'_'\n",
        "else:\n",
        "    name='random'+list2str(nums)+'_'+str(T_frames-nums[-1])+'_'\n",
        "framenums=range(nums[-1]+1,T_frames+1) # range(3,4)\n",
        "\n",
        "tex_layers=['conv1_1', 'conv2_1', 'conv3_1', 'conv4_1', 'conv5_1']\n",
        "im_size=resize_images()\n",
        "vggnet = build_model(im_size)\n",
        "read_model_data(vggnet['pool5'], 'normalized_vgg19_weights.weights')\n",
        "\n",
        "source_gram_s, bounds=get_bounds_and_source_gram()\n",
        "generate_frames(source_gram_s, bounds)   \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}